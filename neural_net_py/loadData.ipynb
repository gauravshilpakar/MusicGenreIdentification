{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbasecondade00ac545d9943b79f901a1085f41842",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "AUDIO_DIR = 'C:\\\\Users\\\\gaura\\\\Desktop\\\\fma_small'\n",
    "META_DIR = 'C:\\\\Users\\\\gaura\\\\Desktop\\\\fma_metadata\\\\tracks.csv'\n",
    "\n",
    "PATH = 'audio_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tids_from_directory(audio_dir):\n",
    "    \"\"\"Get track IDs from the mp3s in a directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    audio_dir : str\n",
    "        Path to the directory where the audio files are stored.\n",
    "    Returns\n",
    "    -------\n",
    "        A list of track IDs.\n",
    "    \"\"\"\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "8000"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tids = get_tids_from_directory(AUDIO_DIR)\n",
    "\n",
    "len(tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_calc(track_id):\n",
    "    # filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "    name = get_audio_path(AUDIO_DIR, track_id) \n",
    "    x, fs = librosa.load(name)\n",
    "    # librosa.display.waveplot(x, sr=fs)\n",
    "    mfcc = librosa.feature.melspectrogram(\n",
    "        x, sr=fs, power=2.0,  n_fft=2048, hop_length=512)\n",
    "    # plt.savefig(f\"spectral_outputs/{file_name.split('.')[0]}_spectrogram.png\")\n",
    "    power_db = librosa.power_to_db(mfcc, ref=np.max)\n",
    "\n",
    "    # plt.figure()\n",
    "    # librosa.display.specshow(power_db, sr=fs, x_axis='time', y_axis='mel')\n",
    "    # plt.colorbar(format='%+2.0f dB')\n",
    "    # plt.title(str(track_id))\n",
    "    # # plt.title(str(genre))\n",
    "    # plt.savefig(f\"spectral_outputs/{file_name.split('.')[0]}_melscale.png\")\n",
    "    # print(f\"Saving to file: {genre}.png\")\n",
    "    print(f\"Sampling Rate: {fs}\")\n",
    "    print(f\"Processing File: {name}\")\n",
    "    # plt.savefig(f\"spectral_outputs/{genre}_melscale.png\")\n",
    "\n",
    "    # fft(x, fs, file_name)\n",
    "    return power_db.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft(x, fs, file_name):\n",
    "    X = scipy.fft.fft(x)\n",
    "    X_mag = np.absolute(X)\n",
    "    f = np.linspace(0, fs, len(X_mag))\n",
    "    plt.figure()\n",
    "    plt.plot(f, X_mag)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.savefig(f\"spectral_outputs/{file_name.split('.')[0]}_fft.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">set</th>\n      <th>track</th>\n      <th>track_id</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>split</th>\n      <th>subset</th>\n      <th>genre_top</th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>track_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Hip-Hop</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Pop</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>140</td>\n    </tr>\n    <tr>\n      <td>141</td>\n      <td>training</td>\n      <td>small</td>\n      <td>Folk</td>\n      <td>141</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "               set            track track_id\n             split subset genre_top         \ntrack_id                                    \n2         training  small   Hip-Hop        2\n5         training  small   Hip-Hop        5\n10        training  small       Pop       10\n140       training  small      Folk      140\n141       training  small      Folk      141"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks = pd.read_csv(META_DIR, index_col=0, header=[0, 1])\n",
    "keep_cols = [('set', 'split'),('set', 'subset'),('track', 'genre_top')]\n",
    "\n",
    "df_all = tracks[keep_cols]\n",
    "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
    "\n",
    "df_all['track_id'] = df_all.index\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "training      6400\ntest           800\nvalidation     800\nName: (set, split), dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[('set', 'split')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " y = pd.DataFrame(tracks.columns)\n",
    " y.to_csv('trackinfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[256000 192000 128000 ... 319784 320172 320453]\nMax: 448000\nMin: -1\nAverage: 230190.04919528787\nStandard Deviation: 51891.9852258237\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Measures</th>\n      <th>Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Max</td>\n      <td>448000.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Min</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Avg</td>\n      <td>230190.049195</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Std</td>\n      <td>51891.985226</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Measures         Values\n0      Max  448000.000000\n1      Min      -1.000000\n2      Avg  230190.049195\n3      Std   51891.985226"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(tracks[('track','bit_rate')].unique())\n",
    "print(y)\n",
    "print(f\"Max: {y.max()}\")\n",
    "print(f\"Min: {y.min()}\")\n",
    "print(f\"Average: {y.mean()}\")\n",
    "print(f\"Standard Deviation: {y.std()}\")\n",
    "\n",
    "info = {\"Measures\":[\"Max\", \"Min\", \"Avg\",\"Std\"],\"Values\": [y.max(), y.min(), y.mean(),y.std()]}\n",
    "scale = pd.DataFrame(info)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'Electronic':1, 'Experimental':2, 'Folk':3, 'Hip-Hop':4, 'Instrumental':5,'International':6, 'Pop' :7, 'Rock': 8  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(df):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, 128))\n",
    "    count = 0\n",
    "    #Code skips records in case of errors\n",
    "    for index, row in df.iterrows():\n",
    "        count += 1\n",
    "        track_id = int(row['track_id'])\n",
    "        genre = str(row[('track', 'genre_top')])\n",
    "        spect = mfcc_calc(track_id)\n",
    "        # Normalize for small shape differences\n",
    "        spect = spect[:640, :]\n",
    "        X_spect = np.append(X_spect, [spect], axis=0)            \n",
    "        genres.append(dict_genres[genre])\n",
    "        if count % 100 == 0:\n",
    "            print(\"Currently processing: \", count)\n",
    "        \n",
    "    y_arr = np.array(genres)\n",
    "    return X_spect, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_all[df_all[(\"set\", \"split\")]==\"training\"]\n",
    "test = df_all[df_all[(\"set\", \"split\")]==\"test\"]\n",
    "validation = df_all[df_all[(\"set\", \"split\")]==\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "((6400, 4), (800, 4), (800, 4))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Sampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\nSampling Rate: 22050\n"
    }
   ],
   "source": [
    "X_test, y_test = create_array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}